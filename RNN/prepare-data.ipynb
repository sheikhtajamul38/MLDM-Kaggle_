{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":1854.752652,"end_time":"2023-10-13T02:24:31.866910","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-10-13T01:53:37.114258","version":"2.4.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"085258944f3b486e80d8c3c789d3238d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"185afcb56f4c442bb1fe94d20493d6e0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9eec2947102d44a98f2b48ce2d2668b8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a53173aeb6764014bac0ba6fafc75a4f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"acd8714cd0ea4c28a2e8e83eb22163ac":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_085258944f3b486e80d8c3c789d3238d","max":277,"min":0,"orientation":"horizontal","style":"IPY_MODEL_a53173aeb6764014bac0ba6fafc75a4f","value":277}},"b4477211f85248f699fafc45ea174796":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cc34047bf6ca486184e668b71463f10a","placeholder":"​","style":"IPY_MODEL_c0d39d6589e74b0fba62b432ff3e4072","value":"100%"}},"c0d39d6589e74b0fba62b432ff3e4072":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca152409810447b98c17d212f6f859fb":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_daaad2a4e7304906aea948285e44353f","placeholder":"​","style":"IPY_MODEL_9eec2947102d44a98f2b48ce2d2668b8","value":" 277/277 [27:45&lt;00:00,  7.58s/it]"}},"cc34047bf6ca486184e668b71463f10a":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cf91544647a5432a9a62fb3361ca008f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b4477211f85248f699fafc45ea174796","IPY_MODEL_acd8714cd0ea4c28a2e8e83eb22163ac","IPY_MODEL_ca152409810447b98c17d212f6f859fb"],"layout":"IPY_MODEL_185afcb56f4c442bb1fe94d20493d6e0"}},"daaad2a4e7304906aea948285e44353f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}},"version_major":2,"version_minor":0}},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"Finding Critical Points using RNNs\n\nCredits:\n - dataloader: https://www.kaggle.com/code/henriupton/efficient-loading-memory-usage-visualizations-cmi","metadata":{"papermill":{"duration":0.002856,"end_time":"2023-10-13T01:53:40.395162","exception":false,"start_time":"2023-10-13T01:53:40.392306","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc\nimport time\nimport json\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport os\nimport joblib\nimport random\nimport math\nfrom tqdm.auto import tqdm \n\nfrom scipy.interpolate import interp1d\n\nfrom math import pi, sqrt, exp\nimport sklearn,sklearn.model_selection\nimport torch\nfrom torch import nn,Tensor\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\nfrom sklearn.metrics import average_precision_score\nfrom timm.scheduler import CosineLRScheduler\nplt.style.use(\"ggplot\")\n\nfrom pyarrow.parquet import ParquetFile\nimport pyarrow as pa \nimport ctypes","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-13T01:53:40.404034Z","iopub.status.busy":"2023-10-13T01:53:40.403399Z","iopub.status.idle":"2023-10-13T01:53:48.270243Z","shell.execute_reply":"2023-10-13T01:53:48.269439Z"},"papermill":{"duration":7.874869,"end_time":"2023-10-13T01:53:48.272549","exception":false,"start_time":"2023-10-13T01:53:40.397680","status":"completed"},"tags":[]},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class PATHS:\n    MAIN_DIR = \"/kaggle/input/child-mind-institute-detect-sleep-states/\"\n    # CSV FILES : \n    SUBMISSION = MAIN_DIR + \"sample_submission.csv\"\n    TRAIN_EVENTS = MAIN_DIR + \"train_events.csv\"\n    # PARQUET FILES:\n    TRAIN_SERIES = MAIN_DIR + \"train_series.parquet\"\n    TEST_SERIES = MAIN_DIR + \"test_series.parquet\"","metadata":{"execution":{"iopub.execute_input":"2023-10-13T01:53:48.279591Z","iopub.status.busy":"2023-10-13T01:53:48.278968Z","iopub.status.idle":"2023-10-13T01:53:48.283734Z","shell.execute_reply":"2023-10-13T01:53:48.282737Z"},"papermill":{"duration":0.010957,"end_time":"2023-10-13T01:53:48.286150","exception":false,"start_time":"2023-10-13T01:53:48.275193","status":"completed"},"tags":[]},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"class CFG:\n    DEMO_MODE = True","metadata":{"execution":{"iopub.execute_input":"2023-10-13T01:53:48.292625Z","iopub.status.busy":"2023-10-13T01:53:48.292251Z","iopub.status.idle":"2023-10-13T01:53:48.297256Z","shell.execute_reply":"2023-10-13T01:53:48.296432Z"},"papermill":{"duration":0.010476,"end_time":"2023-10-13T01:53:48.299103","exception":false,"start_time":"2023-10-13T01:53:48.288627","status":"completed"},"tags":[]},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class data_reader:\n    def __init__(self, demo_mode):\n        super().__init__()\n        # MAPPING FOR DATA LOADING :\n        self.names_mapping = {\n            \"submission\" : {\"path\" : PATHS.SUBMISSION, \"is_parquet\" : False, \"has_timestamp\" : False}, \n            \"train_events\" : {\"path\" : PATHS.TRAIN_EVENTS, \"is_parquet\" : False, \"has_timestamp\" : True},\n            \"train_series\" : {\"path\" : PATHS.TRAIN_SERIES, \"is_parquet\" : True, \"has_timestamp\" : True},\n            \"test_series\" : {\"path\" : PATHS.TEST_SERIES, \"is_parquet\" : True, \"has_timestamp\" : True}\n        }\n        self.valid_names = [\"submission\", \"train_events\", \"train_series\", \"test_series\"]\n        self.demo_mode = demo_mode\n    \n    def verify(self, data_name):\n        \"function for data name verification\"\n        if data_name not in self.valid_names:\n            print(\"PLEASE ENTER A VALID DATASET NAME, VALID NAMES ARE : \", valid_names)\n        return\n    \n    def cleaning(self, data):\n        \"cleaning function : drop na values\"\n        before_cleaning = len(data)\n        print(\"Number of missing timestamps : \", len(data[data[\"timestamp\"].isna()]))\n        data = data.dropna(subset=[\"timestamp\"])\n        after_cleaning = len(data)\n        print(\"Percentage of removed steps : {:.1f}%\".format(100 * (before_cleaning - after_cleaning) / before_cleaning) )\n#         print(data.isna().any())\n#         data = data.bfill()\n        return data\n    \n    @staticmethod\n    def reduce_memory_usage(data):\n        \"iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\"\n        start_mem = data.memory_usage().sum() / 1024**2\n        print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n        for col in data.columns:\n            col_type = data[col].dtype    \n            if col_type != object:\n                c_min = data[col].min()\n                c_max = data[col].max()\n                if str(col_type)[:3] == 'int':\n                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                        data[col] = data[col].astype(np.int8)\n                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                        data[col] = data[col].astype(np.int16)\n                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                        data[col] = data[col].astype(np.int32)\n                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                        data[col] = data[col].astype(np.int64)  \n                else:\n                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                        data[col] = data[col].astype(np.float16)\n                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                        data[col] = data[col].astype(np.float32)\n                    else:\n                        data[col] = data[col].astype(np.float64)\n            else:\n                data[col] = data[col].astype('category')\n\n        end_mem = data.memory_usage().sum() / 1024**2\n        print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n        print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n        return data\n    \n    def load_data(self, data_name):\n        \"function for data loading\"\n        self.verify(data_name)\n        data_props = self.names_mapping[data_name]\n        if data_props[\"is_parquet\"]:\n            if self.demo_mode:\n                pf = ParquetFile(data_props[\"path\"]) \n                demo_steps = next(pf.iter_batches(batch_size=20_000)) \n                data = pa.Table.from_batches([demo_steps]).to_pandas()\n            else:\n                data = pd.read_parquet(data_props[\"path\"])\n        else:\n            if self.demo_mode:\n                data = pd.read_csv(data_props[\"path\"], nsteps=20_000)\n            else:\n                data = pd.read_csv(data_props[\"path\"])\n                \n        gc.collect()\n        if data_props[\"has_timestamp\"]:\n            print('cleaning')\n            data = self.cleaning(data)\n            gc.collect()\n        data = self.reduce_memory_usage(data)\n        return data","metadata":{"execution":{"iopub.execute_input":"2023-10-13T01:53:48.306173Z","iopub.status.busy":"2023-10-13T01:53:48.305539Z","iopub.status.idle":"2023-10-13T01:53:48.323582Z","shell.execute_reply":"2023-10-13T01:53:48.322198Z"},"papermill":{"duration":0.024686,"end_time":"2023-10-13T01:53:48.326279","exception":false,"start_time":"2023-10-13T01:53:48.301593","status":"completed"},"tags":[]},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"reader = data_reader(demo_mode=False)\nseries = reader.load_data(data_name=\"train_series\")\nevents = reader.load_data(data_name=\"train_events\")","metadata":{"execution":{"iopub.execute_input":"2023-10-13T01:53:48.334186Z","iopub.status.busy":"2023-10-13T01:53:48.333512Z","iopub.status.idle":"2023-10-13T01:56:40.566680Z","shell.execute_reply":"2023-10-13T01:56:40.565696Z"},"papermill":{"duration":172.240081,"end_time":"2023-10-13T01:56:40.568947","exception":false,"start_time":"2023-10-13T01:53:48.328866","status":"completed"},"tags":[]},"execution_count":5,"outputs":[{"name":"stdout","output_type":"stream","text":"cleaning\n\nNumber of missing timestamps :  0\n\nPercentage of removed steps : 0.0%\n\nMemory usage of dataframe is 3416.54 MB\n\nMemory usage after optimization is: 2059.05 MB\n\nDecreased by 39.7%\n\ncleaning\n\nNumber of missing timestamps :  4923\n\nPercentage of removed steps : 33.9%\n\nMemory usage of dataframe is 0.44 MB\n\nMemory usage after optimization is: 0.50 MB\n\nDecreased by -13.5%\n"}]},{"cell_type":"code","source":"targets = []\ndata = []\nids = series.series_id.unique()\n\nfor viz_id in tqdm(ids):\n    viz_targets = []\n    viz_events = events[events.series_id == viz_id]\n    viz_series = series.loc[(series.series_id==viz_id)].copy().reset_index()\n    viz_series['dt'] = pd.to_datetime(viz_series.timestamp,format = '%Y-%m-%dT%H:%M:%S%z').astype(\"datetime64[ns, UTC-04:00]\")\n    viz_series['hour'] = viz_series['dt'].dt.hour\n\n    check = 0\n    for i in range(len(viz_events)-1):\n        if viz_events.iloc[i].event =='onset' and viz_events.iloc[i+1].event =='wakeup' and viz_events.iloc[i].night==viz_events.iloc[i+1].night:\n            start,end = viz_events.timestamp.iloc[i],viz_events.timestamp.iloc[i+1]\n\n            start_id = viz_series.loc[viz_series.timestamp ==start].index.values[0]\n            end_id = viz_series.loc[viz_series.timestamp ==end].index.values[0]\n            viz_targets.append((start_id,end_id))\n            check+=1\n    targets.append(viz_targets)\n    data.append(viz_series[['anglez','enmo','step']]) #you can include features like hour or minnute or second if you want to\njoblib.dump((targets,data,ids), 'train_data.pkl')\nlen(data)","metadata":{"execution":{"iopub.execute_input":"2023-10-13T01:56:40.576546Z","iopub.status.busy":"2023-10-13T01:56:40.575812Z","iopub.status.idle":"2023-10-13T02:24:29.731168Z","shell.execute_reply":"2023-10-13T02:24:29.729802Z"},"papermill":{"duration":1669.161337,"end_time":"2023-10-13T02:24:29.733162","exception":false,"start_time":"2023-10-13T01:56:40.571825","status":"completed"},"tags":[]},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"cf91544647a5432a9a62fb3361ca008f","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/277 [00:00<?, ?it/s]"]},"metadata":{}},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":["277"]},"metadata":{}}]}]}