{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"papermill":{"default_parameters":{},"duration":15.463152,"end_time":"2023-10-18T23:14:11.802567","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2023-10-18T23:13:56.339415","version":"2.4.0"},"widgets":{"application/vnd.jupyter.widget-state+json":{"state":{"0d3b9ae46d8347fea497d2c355d1f7f2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e28e5041abce4d529995ef064cbfe24b","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2cd6cb6501d94b94b8179226fa523a68","value":3}},"2abb91b00a6c4b84bf0e122f73710789":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2cd6cb6501d94b94b8179226fa523a68":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"52f8838c09774ca38b6b1a971eab1d64":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"683e3962dc924f1481cb065d5703f9ff":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8880497c99cd419da58a9278ebb5860e","placeholder":"​","style":"IPY_MODEL_52f8838c09774ca38b6b1a971eab1d64","value":" 3/3 [00:00&lt;00:00, 197.60it/s]"}},"8880497c99cd419da58a9278ebb5860e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad18c5106dd04c6c8774e0776e7c33d6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fe0276ff65b14100a4e5079bc805c1d8","IPY_MODEL_0d3b9ae46d8347fea497d2c355d1f7f2","IPY_MODEL_683e3962dc924f1481cb065d5703f9ff"],"layout":"IPY_MODEL_dc17eb0dcdcb44c3bc0db2c7dc1cebbd"}},"dc17eb0dcdcb44c3bc0db2c7dc1cebbd":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e28e5041abce4d529995ef064cbfe24b":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fbf98002673b416f88d11c2c1e2ac7a5":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fe0276ff65b14100a4e5079bc805c1d8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fbf98002673b416f88d11c2c1e2ac7a5","placeholder":"​","style":"IPY_MODEL_2abb91b00a6c4b84bf0e122f73710789","value":"100%"}}},"version_major":2,"version_minor":0}},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30626,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Finding Critical Points using RNNs\n\n\nCredits:\n\n - idea: https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states/discussion/441470\n - dataloader: https://www.kaggle.com/code/henriupton/efficient-loading-memory-usage-visualizations-cmi\n - arch: https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/discussion/416410","metadata":{"papermill":{"duration":0.002533,"end_time":"2023-10-18T23:14:00.206907","exception":false,"start_time":"2023-10-18T23:14:00.204374","status":"completed"},"tags":[]}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport gc\nimport time\nimport json\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nimport os\nimport joblib\nimport random\nimport math\nfrom tqdm.auto import tqdm \n\nfrom scipy.interpolate import interp1d\n\nfrom math import pi, sqrt, exp\nimport sklearn,sklearn.model_selection\nimport torch\nfrom torch import nn,Tensor\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\nfrom sklearn.metrics import average_precision_score\nfrom timm.scheduler import CosineLRScheduler\nplt.style.use(\"ggplot\")\n\nfrom pyarrow.parquet import ParquetFile\nimport pyarrow as pa \nimport ctypes\ntorch.set_num_interop_threads(4)\ntorch.set_num_threads(4)\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-18T23:14:00.214734Z","iopub.status.busy":"2023-10-18T23:14:00.214163Z","iopub.status.idle":"2023-10-18T23:14:08.171208Z","shell.execute_reply":"2023-10-18T23:14:08.170492Z"},"papermill":{"duration":7.964505,"end_time":"2023-10-18T23:14:08.173454","exception":false,"start_time":"2023-10-18T23:14:00.208949","status":"completed"},"tags":[]},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"class PATHS:\n    MAIN_DIR = \"/kaggle/input/child-mind-institute-detect-sleep-states/\"\n    # CSV FILES : \n    SUBMISSION = MAIN_DIR + \"sample_submission.csv\"\n    TRAIN_EVENTS = MAIN_DIR + \"train_events.csv\"\n    # PARQUET FILES:\n    TRAIN_SERIES = MAIN_DIR + \"train_series.parquet\"\n    TEST_SERIES = MAIN_DIR + \"test_series.parquet\"\nclass CFG:\n    DEMO_MODE = True\nclass data_reader:\n    def __init__(self, demo_mode):\n        super().__init__()\n        # MAPPING FOR DATA LOADING :\n        self.names_mapping = {\n            \"submission\" : {\"path\" : PATHS.SUBMISSION, \"is_parquet\" : False, \"has_timestamp\" : False}, \n            \"train_events\" : {\"path\" : PATHS.TRAIN_EVENTS, \"is_parquet\" : False, \"has_timestamp\" : True},\n            \"train_series\" : {\"path\" : PATHS.TRAIN_SERIES, \"is_parquet\" : True, \"has_timestamp\" : True},\n            \"test_series\" : {\"path\" : PATHS.TEST_SERIES, \"is_parquet\" : True, \"has_timestamp\" : True}\n        }\n        self.valid_names = [\"submission\", \"train_events\", \"train_series\", \"test_series\"]\n        self.demo_mode = demo_mode\n    \n    def verify(self, data_name):\n        \"function for data name verification\"\n        if data_name not in self.valid_names:\n            print(\"PLEASE ENTER A VALID DATASET NAME, VALID NAMES ARE : \", valid_names)\n        return\n    \n    def cleaning(self, data):\n        \"cleaning function : drop na values\"\n        before_cleaning = len(data)\n        print(\"Number of missing timestamps : \", len(data[data[\"timestamp\"].isna()]))\n        data = data.dropna(subset=[\"timestamp\"])\n        after_cleaning = len(data)\n        print(\"Percentage of removed rows : {:.1f}%\".format(100 * (before_cleaning - after_cleaning) / before_cleaning) )\n#         print(data.isna().any())\n#         data = data.bfill()\n        return data\n    \n    @staticmethod\n    def reduce_memory_usage(data):\n        \"iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\"\n        start_mem = data.memory_usage().sum() / 1024**2\n        print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n        for col in data.columns:\n            col_type = data[col].dtype    \n            if col_type != object:\n                c_min = data[col].min()\n                c_max = data[col].max()\n                if str(col_type)[:3] == 'int':\n                    if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                        data[col] = data[col].astype(np.int8)\n                    elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                        data[col] = data[col].astype(np.int16)\n                    elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                        data[col] = data[col].astype(np.int32)\n                    elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                        data[col] = data[col].astype(np.int64)  \n                else:\n                    if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                        data[col] = data[col].astype(np.float16)\n                    elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                        data[col] = data[col].astype(np.float32)\n                    else:\n                        data[col] = data[col].astype(np.float64)\n            else:\n                data[col] = data[col].astype('category')\n\n        end_mem = data.memory_usage().sum() / 1024**2\n        print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n        print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n        return data\n    \n    def load_data(self, data_name):\n        \"function for data loading\"\n        self.verify(data_name)\n        data_props = self.names_mapping[data_name]\n        if data_props[\"is_parquet\"]:\n            if self.demo_mode:\n                pf = ParquetFile(data_props[\"path\"]) \n                demo_rows = next(pf.iter_batches(batch_size=20_000)) \n                data = pa.Table.from_batches([demo_rows]).to_pandas()\n            else:\n                data = pd.read_parquet(data_props[\"path\"])\n        else:\n            if self.demo_mode:\n                data = pd.read_csv(data_props[\"path\"], nrows=20_000)\n            else:\n                data = pd.read_csv(data_props[\"path\"])\n                \n        gc.collect()\n        if data_props[\"has_timestamp\"]:\n            print('cleaning')\n            data = self.cleaning(data)\n            gc.collect()\n        data = self.reduce_memory_usage(data)\n        return data","metadata":{"execution":{"iopub.execute_input":"2023-10-18T23:14:08.181488Z","iopub.status.busy":"2023-10-18T23:14:08.180216Z","iopub.status.idle":"2023-10-18T23:14:08.196253Z","shell.execute_reply":"2023-10-18T23:14:08.195564Z"},"papermill":{"duration":0.022683,"end_time":"2023-10-18T23:14:08.198810","exception":false,"start_time":"2023-10-18T23:14:08.176127","status":"completed"},"tags":[]},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"reader = data_reader(demo_mode=False)\ntest_series = reader.load_data(data_name=\"test_series\")\nids = test_series.series_id.unique()\ngc.collect()","metadata":{"execution":{"iopub.execute_input":"2023-10-18T23:14:08.204615Z","iopub.status.busy":"2023-10-18T23:14:08.204049Z","iopub.status.idle":"2023-10-18T23:14:08.808736Z","shell.execute_reply":"2023-10-18T23:14:08.807177Z"},"papermill":{"duration":0.609886,"end_time":"2023-10-18T23:14:08.810950","exception":false,"start_time":"2023-10-18T23:14:08.201064","status":"completed"},"tags":[]},"execution_count":3,"outputs":[{"name":"stdout","output_type":"stream","text":"cleaning\n\nNumber of missing timestamps :  0\n\nPercentage of removed rows : 0.0%\n\nMemory usage of dataframe is 0.01 MB\n\nMemory usage after optimization is: 0.02 MB\n\nDecreased by -92.2%\n"},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":["0"]},"metadata":{}}]},{"cell_type":"code","source":"class ResidualBiGRU(nn.Module):\n    def __init__(self, hidden_size, n_layers=1, bidir=True):\n        super(ResidualBiGRU, self).__init__()\n\n        self.hidden_size = hidden_size\n        self.n_layers = n_layers\n\n        self.gru = nn.GRU(\n            hidden_size,\n            hidden_size,\n            n_layers,\n            batch_first=True,\n            bidirectional=bidir,\n        )\n        dir_factor = 2 if bidir else 1\n        self.fc1 = nn.Linear(\n            hidden_size * dir_factor, hidden_size * dir_factor * 2\n        )\n        self.ln1 = nn.LayerNorm(hidden_size * dir_factor * 2)\n        self.fc2 = nn.Linear(hidden_size * dir_factor * 2, hidden_size)\n        self.ln2 = nn.LayerNorm(hidden_size)\n\n    def forward(self, x, h=None):\n        res, new_h = self.gru(x, h)\n        # res.shape = (batch_size, sequence_size, 2*hidden_size)\n\n        res = self.fc1(res)\n        res = self.ln1(res)\n        res = nn.functional.relu(res)\n\n        res = self.fc2(res)\n        res = self.ln2(res)\n        res = nn.functional.relu(res)\n\n        # skip connection\n        res = res + x\n\n        return res, new_h\n\nclass MultiResidualBiGRU(nn.Module):\n    def __init__(self, input_size, hidden_size, out_size, n_layers, bidir=True):\n        super(MultiResidualBiGRU, self).__init__()\n\n        self.input_size = input_size\n        self.hidden_size = hidden_size\n        self.out_size = out_size\n        self.n_layers = n_layers\n\n        self.fc_in = nn.Linear(input_size, hidden_size)\n        self.ln = nn.LayerNorm(hidden_size)\n        self.res_bigrus = nn.ModuleList(\n            [\n                ResidualBiGRU(hidden_size, n_layers=1, bidir=bidir)\n                for _ in range(n_layers)\n            ]\n        )\n        self.fc_out = nn.Linear(hidden_size, out_size)\n\n    def forward(self, x, h=None):\n        # if we are at the beginning of a sequence (no hidden state)\n        if h is None:\n            # (re)initialize the hidden state\n            h = [None for _ in range(self.n_layers)]\n\n        x = self.fc_in(x)\n        x = self.ln(x)\n        x = nn.functional.relu(x)\n\n        new_h = []\n        for i, res_bigru in enumerate(self.res_bigrus):\n            x, new_hi = res_bigru(x, h[i])\n            new_h.append(new_hi)\n\n        x = self.fc_out(x)\n#         x = F.normalize(x,dim=0)\n        return x, new_h  # log probabilities + hidden states","metadata":{"execution":{"iopub.execute_input":"2023-10-18T23:14:08.817970Z","iopub.status.busy":"2023-10-18T23:14:08.816563Z","iopub.status.idle":"2023-10-18T23:14:08.827166Z","shell.execute_reply":"2023-10-18T23:14:08.826219Z"},"papermill":{"duration":0.015415,"end_time":"2023-10-18T23:14:08.828854","exception":false,"start_time":"2023-10-18T23:14:08.813439","status":"completed"},"tags":[]},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"class SleepDataset(Dataset):\n    def __init__(\n        self,\n        series_ids,\n        series,\n    ):\n        series_ids = series_ids\n        series = series.reset_index()\n        self.data = []\n        \n        for viz_id in tqdm(series_ids):\n            self.data.append(series.loc[(series.series_id==viz_id)].copy().reset_index())\n            \n    def downsample_seq_generate_features(self,feat, downsample_factor):\n        \n        if len(feat)%12!=0:\n            feat = np.concatenate([feat,np.zeros(12-((len(feat))%12))+feat[-1]])\n        feat = np.reshape(feat, (-1,12))\n        feat_mean = np.mean(feat,1)\n        feat_std = np.std(feat,1)\n        feat_median = np.median(feat,1)\n        feat_max = np.max(feat,1)\n        feat_min = np.min(feat,1)\n\n        return np.dstack([feat_mean,feat_std,feat_median,feat_max,feat_min])[0]\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, index):\n        X = self.data[index][['anglez','enmo']].values.astype(np.float32)\n        X = np.concatenate([self.downsample_seq_generate_features(X[:,i],12) for i in range(X.shape[1])],-1)\n        X = torch.from_numpy(X)\n        return X\ntest_ds = SleepDataset(test_series.series_id.unique(),test_series)\ndel test_series\ngc.collect()","metadata":{"execution":{"iopub.execute_input":"2023-10-18T23:14:08.835380Z","iopub.status.busy":"2023-10-18T23:14:08.834833Z","iopub.status.idle":"2023-10-18T23:14:09.014057Z","shell.execute_reply":"2023-10-18T23:14:09.012769Z"},"papermill":{"duration":0.185209,"end_time":"2023-10-18T23:14:09.016533","exception":false,"start_time":"2023-10-18T23:14:08.831324","status":"completed"},"tags":[]},"execution_count":5,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"ad18c5106dd04c6c8774e0776e7c33d6","version_major":2,"version_minor":0},"text/plain":["  0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":["22"]},"metadata":{}}]},{"cell_type":"code","source":"max_chunk_size = 24*60*100\nmin_interval = 30","metadata":{"execution":{"iopub.execute_input":"2023-10-18T23:14:09.023356Z","iopub.status.busy":"2023-10-18T23:14:09.022748Z","iopub.status.idle":"2023-10-18T23:14:09.027526Z","shell.execute_reply":"2023-10-18T23:14:09.026253Z"},"papermill":{"duration":0.010196,"end_time":"2023-10-18T23:14:09.029435","exception":false,"start_time":"2023-10-18T23:14:09.019239","status":"completed"},"tags":[]},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"model = MultiResidualBiGRU(input_size=10,hidden_size=64,out_size=2,n_layers=5).to(device).eval()\nmodel.load_state_dict(torch.load(f'/kaggle/input/sleep-critical-point-train/model_best.pth',map_location=device))\nsubmission = pd.DataFrame()\nfor i in range(len(test_ds)):\n    X = test_ds[i].half()\n    \n    seq_len = X.shape[0]\n    h = None\n    pred = torch.zeros((len(X),2)).half()\n    for j in range(0, seq_len, max_chunk_size):\n        y_pred, h = model(X[j: j + max_chunk_size].float(), h)\n        h = [hi.detach() for hi in h]\n        pred[j : j + max_chunk_size] = y_pred.detach()\n        del y_pred;gc.collect()\n    del h,X;gc.collect()\n    pred = pred.numpy()\n    \n    series_id = ids[i]\n    \n    days = len(pred)/(17280/12)\n    scores0,scores1 = np.zeros(len(pred),dtype=np.float16),np.zeros(len(pred),dtype=np.float16)\n    for index in range(len(pred)):\n        if pred[index,0]==max(pred[max(0,index-min_interval):index+min_interval,0]):\n            scores0[index] = max(pred[max(0,index-min_interval):index+min_interval,0])\n        if pred[index,1]==max(pred[max(0,index-min_interval):index+min_interval,1]):\n            scores1[index] = max(pred[max(0,index-min_interval):index+min_interval,1])\n    candidates_onset = np.argsort(scores0)[-max(1,round(days)):]\n    candidates_wakeup = np.argsort(scores1)[-max(1,round(days)):]\n    \n    onset = test_ds.data[i][['step']].iloc[np.clip(candidates_onset*12,0,len(test_ds.data[i])-1)].astype(np.int32)\n    onset['event'] = 'onset'\n    onset['series_id'] = series_id\n    onset['score']= scores0[candidates_onset]\n    wakeup = test_ds.data[i][['step']].iloc[np.clip(candidates_wakeup*12,0,len(test_ds.data[i])-1)].astype(np.int32)\n    wakeup['event'] = 'wakeup'\n    wakeup['series_id'] = series_id\n    wakeup['score']= scores1[candidates_wakeup]\n    submission = pd.concat([submission,onset,wakeup],axis=0)\n    del onset,wakeup,candidates_onset,candidates_wakeup,scores0,scores1,pred,series_id,\n    gc.collect()\nsubmission = submission.sort_values(['series_id','step']).reset_index(drop=True)\nsubmission['row_id'] = submission.index.astype(int)\nsubmission['score'] = submission['score'].fillna(submission['score'].mean())\nsubmission = submission[['row_id','series_id','step','event','score']]\nsubmission.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.execute_input":"2023-10-18T23:14:09.035610Z","iopub.status.busy":"2023-10-18T23:14:09.035306Z","iopub.status.idle":"2023-10-18T23:14:10.656048Z","shell.execute_reply":"2023-10-18T23:14:10.654511Z"},"papermill":{"duration":1.62678,"end_time":"2023-10-18T23:14:10.658889","exception":false,"start_time":"2023-10-18T23:14:09.032109","status":"completed"},"tags":[]},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"submission","metadata":{"execution":{"iopub.execute_input":"2023-10-18T23:14:10.666141Z","iopub.status.busy":"2023-10-18T23:14:10.665790Z","iopub.status.idle":"2023-10-18T23:14:10.678202Z","shell.execute_reply":"2023-10-18T23:14:10.677328Z"},"papermill":{"duration":0.017502,"end_time":"2023-10-18T23:14:10.679758","exception":false,"start_time":"2023-10-18T23:14:10.662256","status":"completed"},"tags":[]},"execution_count":8,"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>row_id</th>\n","      <th>series_id</th>\n","      <th>step</th>\n","      <th>event</th>\n","      <th>score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>038441c925bb</td>\n","      <td>0</td>\n","      <td>onset</td>\n","      <td>0.237427</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>038441c925bb</td>\n","      <td>144</td>\n","      <td>wakeup</td>\n","      <td>0.049408</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>03d92c9f6f8a</td>\n","      <td>36</td>\n","      <td>onset</td>\n","      <td>0.179810</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>03d92c9f6f8a</td>\n","      <td>144</td>\n","      <td>wakeup</td>\n","      <td>0.016251</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0402a003dae9</td>\n","      <td>60</td>\n","      <td>wakeup</td>\n","      <td>0.013649</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>0402a003dae9</td>\n","      <td>144</td>\n","      <td>onset</td>\n","      <td>0.094360</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   row_id     series_id  step   event     score\n","0       0  038441c925bb     0   onset  0.237427\n","1       1  038441c925bb   144  wakeup  0.049408\n","2       2  03d92c9f6f8a    36   onset  0.179810\n","3       3  03d92c9f6f8a   144  wakeup  0.016251\n","4       4  0402a003dae9    60  wakeup  0.013649\n","5       5  0402a003dae9   144   onset  0.094360"]},"metadata":{}}]}]}