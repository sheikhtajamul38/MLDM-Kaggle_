{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 15.463152,
      "end_time": "2023-10-18T23:14:11.802567",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-10-18T23:13:56.339415",
      "version": "2.4.0"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [],
      "dockerImageVersionId": 30626,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Finding Critical Points using RNNs\n",
        "\n",
        "\n",
        "Credits:\n",
        "\n",
        " - idea: https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states/discussion/441470\n",
        " - dataloader: https://www.kaggle.com/code/henriupton/efficient-loading-memory-usage-visualizations-cmi\n",
        " - arch: https://www.kaggle.com/competitions/tlvmc-parkinsons-freezing-gait-prediction/discussion/416410"
      ],
      "metadata": {
        "papermill": {
          "duration": 0.002533,
          "end_time": "2023-10-18T23:14:00.206907",
          "exception": false,
          "start_time": "2023-10-18T23:14:00.204374",
          "status": "completed"
        },
        "tags": [],
        "id": "4fUm4vtKGTaH"
      },
      "id": "4fUm4vtKGTaH"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "import time\n",
        "import json\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import joblib\n",
        "import random\n",
        "import math\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "from scipy.interpolate import interp1d\n",
        "\n",
        "from math import pi, sqrt, exp\n",
        "import sklearn,sklearn.model_selection\n",
        "import torch\n",
        "from torch import nn,Tensor\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset, SubsetRandomSampler\n",
        "from sklearn.metrics import average_precision_score\n",
        "from timm.scheduler import CosineLRScheduler\n",
        "plt.style.use(\"ggplot\")\n",
        "\n",
        "from pyarrow.parquet import ParquetFile\n",
        "import pyarrow as pa\n",
        "import ctypes\n",
        "torch.set_num_interop_threads(4)\n",
        "torch.set_num_threads(4)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-10-18T23:14:00.214734Z",
          "iopub.status.busy": "2023-10-18T23:14:00.214163Z",
          "iopub.status.idle": "2023-10-18T23:14:08.171208Z",
          "shell.execute_reply": "2023-10-18T23:14:08.170492Z"
        },
        "papermill": {
          "duration": 7.964505,
          "end_time": "2023-10-18T23:14:08.173454",
          "exception": false,
          "start_time": "2023-10-18T23:14:00.208949",
          "status": "completed"
        },
        "tags": [],
        "id": "KWnmKTRjGTaJ"
      },
      "execution_count": null,
      "outputs": [],
      "id": "KWnmKTRjGTaJ"
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyarrow.parquet import ParquetFile\n",
        "import pyarrow as pa\n",
        "import gc\n",
        "\n",
        "class PATHS:\n",
        "    MAIN_DIR = \"/kaggle/input/child-mind-institute-detect-sleep-states/\"\n",
        "    SUBMISSION = MAIN_DIR + \"sample_submission.csv\"\n",
        "    TRAIN_EVENTS = MAIN_DIR + \"train_events.csv\"\n",
        "    TRAIN_SERIES = MAIN_DIR + \"train_series.parquet\"\n",
        "    TEST_SERIES = MAIN_DIR + \"test_series.parquet\"\n",
        "\n",
        "class CFG:\n",
        "    DEMO_MODE = True\n",
        "\n",
        "class data_reader:\n",
        "    def __init__(self, demo_mode):\n",
        "        super().__init__()\n",
        "        # MAPPING FOR DATA LOADING :\n",
        "        self.names_mapping = {\n",
        "            \"submission\": {\"path\": PATHS.SUBMISSION, \"is_parquet\": False, \"has_timestamp\": False},\n",
        "            \"train_events\": {\"path\": PATHS.TRAIN_EVENTS, \"is_parquet\": False, \"has_timestamp\": True},\n",
        "            \"train_series\": {\"path\": PATHS.TRAIN_SERIES, \"is_parquet\": True, \"has_timestamp\": True},\n",
        "            \"test_series\": {\"path\": PATHS.TEST_SERIES, \"is_parquet\": True, \"has_timestamp\": True}\n",
        "        }\n",
        "        self.valid_names = [\"submission\", \"train_events\", \"train_series\", \"test_series\"]\n",
        "        self.demo_mode = demo_mode\n",
        "\n",
        "    def verify(self, data_name):\n",
        "        \"Function for data name verification\"\n",
        "        if data_name not in self.valid_names:\n",
        "            print(\"PLEASE ENTER A VALID DATASET NAME, VALID NAMES ARE: \", self.valid_names)\n",
        "        return\n",
        "\n",
        "    def cleaning(self, data):\n",
        "        \"Cleaning function: drop NA values\"\n",
        "        before_cleaning = len(data)\n",
        "        print(\"Number of missing timestamps: \", len(data[data[\"timestamp\"].isna()]))\n",
        "        data = data.dropna(subset=[\"timestamp\"])\n",
        "        after_cleaning = len(data)\n",
        "        print(\"Percentage of removed rows: {:.1f}%\".format(100 * (before_cleaning - after_cleaning) / before_cleaning))\n",
        "        return data\n",
        "\n",
        "    @staticmethod\n",
        "    def reduce_memory_usage(data):\n",
        "        \"Iterate through all the columns of a dataframe and modify the data type to reduce memory usage.\"\n",
        "        start_mem = data.memory_usage().sum() / 1024 ** 2\n",
        "        print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
        "        for col in data.columns:\n",
        "            col_type = data[col].dtype\n",
        "            if col_type != object:\n",
        "                c_min = data[col].min()\n",
        "                c_max = data[col].max()\n",
        "                if str(col_type)[:3] == 'int':\n",
        "                    for int_type in [np.int8, np.int16, np.int32, np.int64]:\n",
        "                        if c_min > np.iinfo(int_type).min and c_max < np.iinfo(int_type).max:\n",
        "                            data[col] = data[col].astype(int_type)\n",
        "                            break\n",
        "                else:\n",
        "                    for float_type in [np.float16, np.float32, np.float64]:\n",
        "                        if c_min > np.finfo(float_type).min and c_max < np.finfo(float_type).max:\n",
        "                            data[col] = data[col].astype(float_type)\n",
        "                            break\n",
        "            else:\n",
        "                data[col] = data[col].astype('category')\n",
        "\n",
        "        end_mem = data.memory_usage().sum() / 1024 ** 2\n",
        "        print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
        "        print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
        "        return data\n",
        "\n",
        "    def load_data(self, data_name):\n",
        "        \"Function for data loading\"\n",
        "        self.verify(data_name)\n",
        "        data_props = self.names_mapping[data_name]\n",
        "        if data_props[\"is_parquet\"]:\n",
        "            if self.demo_mode:\n",
        "                pf = ParquetFile(data_props[\"path\"])\n",
        "                demo_rows = next(pf.iter_batches(batch_size=20_000))\n",
        "                data = pa.Table.from_batches([demo_rows]).to_pandas()\n",
        "            else:\n",
        "                data = pd.read_parquet(data_props[\"path\"])\n",
        "        else:\n",
        "            if self.demo_mode:\n",
        "                data = pd.read_csv(data_props[\"path\"], nrows=20_000)\n",
        "            else:\n",
        "                data = pd.read_csv(data_props[\"path\"])\n",
        "\n",
        "        gc.collect()\n",
        "        if data_props[\"has_timestamp\"]:\n",
        "            print('Cleaning')\n",
        "            data = self.cleaning(data)\n",
        "            gc.collect()\n",
        "        data = self.reduce_memory_usage(data)\n",
        "        return data\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-18T23:14:08.181488Z",
          "iopub.status.busy": "2023-10-18T23:14:08.180216Z",
          "iopub.status.idle": "2023-10-18T23:14:08.196253Z",
          "shell.execute_reply": "2023-10-18T23:14:08.195564Z"
        },
        "papermill": {
          "duration": 0.022683,
          "end_time": "2023-10-18T23:14:08.198810",
          "exception": false,
          "start_time": "2023-10-18T23:14:08.176127",
          "status": "completed"
        },
        "tags": [],
        "id": "dZ7n81PKGTaL"
      },
      "execution_count": null,
      "outputs": [],
      "id": "dZ7n81PKGTaL"
    },
    {
      "cell_type": "code",
      "source": [
        "reader = data_reader(demo_mode=False)\n",
        "test_series = reader.load_data(data_name=\"test_series\")\n",
        "ids = test_series.series_id.unique()\n",
        "gc.collect()"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-18T23:14:08.204615Z",
          "iopub.status.busy": "2023-10-18T23:14:08.204049Z",
          "iopub.status.idle": "2023-10-18T23:14:08.808736Z",
          "shell.execute_reply": "2023-10-18T23:14:08.807177Z"
        },
        "papermill": {
          "duration": 0.609886,
          "end_time": "2023-10-18T23:14:08.810950",
          "exception": false,
          "start_time": "2023-10-18T23:14:08.201064",
          "status": "completed"
        },
        "tags": [],
        "id": "uzVSoFXIGTaM",
        "outputId": "8c9cc72d-a4c7-4ead-e8af-980057f33703"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "cleaning\n\nNumber of missing timestamps :  0\n\nPercentage of removed rows : 0.0%\n\nMemory usage of dataframe is 0.01 MB\n\nMemory usage after optimization is: 0.02 MB\n\nDecreased by -92.2%\n"
        },
        {
          "execution_count": 3,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {}
        }
      ],
      "id": "uzVSoFXIGTaM"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class ResidualBiGRU(nn.Module):\n",
        "    def __init__(self, hidden_size, n_layers=1, bidir=True):\n",
        "        super(ResidualBiGRU, self).__init__()\n",
        "\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.gru = nn.GRU(\n",
        "            hidden_size,\n",
        "            hidden_size,\n",
        "            n_layers,\n",
        "            batch_first=True,\n",
        "            bidirectional=bidir,\n",
        "        )\n",
        "        dir_factor = 2 if bidir else 1\n",
        "        self.fc1 = nn.Linear(\n",
        "            hidden_size * dir_factor, hidden_size * dir_factor * 2\n",
        "        )\n",
        "        self.ln1 = nn.LayerNorm(hidden_size * dir_factor * 2)\n",
        "        self.fc2 = nn.Linear(hidden_size * dir_factor * 2, hidden_size)\n",
        "        self.ln2 = nn.LayerNorm(hidden_size)\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        res, new_h = self.gru(x, h)\n",
        "        # res.shape = (batch_size, sequence_size, 2*hidden_size)\n",
        "\n",
        "        res = self.fc1(res)\n",
        "        res = self.ln1(res)\n",
        "        res = F.relu(res)\n",
        "\n",
        "        res = self.fc2(res)\n",
        "        res = self.ln2(res)\n",
        "        res = F.relu(res)\n",
        "\n",
        "        # skip connection\n",
        "        res = res + x\n",
        "\n",
        "        return res, new_h\n",
        "\n",
        "class MultiResidualBiGRU(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, out_size, n_layers, bidir=True):\n",
        "        super(MultiResidualBiGRU, self).__init__()\n",
        "\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.out_size = out_size\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.fc_in = nn.Linear(input_size, hidden_size)\n",
        "        self.ln = nn.LayerNorm(hidden_size)\n",
        "        self.res_bigrus = nn.ModuleList(\n",
        "            [\n",
        "                ResidualBiGRU(hidden_size, n_layers=1, bidir=bidir)\n",
        "                for _ in range(n_layers)\n",
        "            ]\n",
        "        )\n",
        "        self.fc_out = nn.Linear(hidden_size, out_size)\n",
        "\n",
        "    def forward(self, x, h=None):\n",
        "        # if we are at the beginning of a sequence (no hidden state)\n",
        "        if h is None:\n",
        "            # (re)initialize the hidden state\n",
        "            h = [None for _ in range(self.n_layers)]\n",
        "\n",
        "        x = self.fc_in(x)\n",
        "        x = self.ln(x)\n",
        "        x = F.relu(x)\n",
        "\n",
        "        new_h = []\n",
        "        for i, res_bigru in enumerate(self.res_bigrus):\n",
        "            x, new_hi = res_bigru(x, h[i])\n",
        "            new_h.append(new_hi)\n",
        "\n",
        "        x = self.fc_out(x)\n",
        "#         x = F.normalize(x, dim=0)\n",
        "        return x, new_h  # log probabilities + hidden states\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-18T23:14:08.817970Z",
          "iopub.status.busy": "2023-10-18T23:14:08.816563Z",
          "iopub.status.idle": "2023-10-18T23:14:08.827166Z",
          "shell.execute_reply": "2023-10-18T23:14:08.826219Z"
        },
        "papermill": {
          "duration": 0.015415,
          "end_time": "2023-10-18T23:14:08.828854",
          "exception": false,
          "start_time": "2023-10-18T23:14:08.813439",
          "status": "completed"
        },
        "tags": [],
        "id": "86dkjiTvGTaM"
      },
      "execution_count": null,
      "outputs": [],
      "id": "86dkjiTvGTaM"
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import gc\n",
        "\n",
        "class SleepDataset(Dataset):\n",
        "    def __init__(self, series_ids, series):\n",
        "        self.data = []\n",
        "\n",
        "        for viz_id in tqdm(series_ids):\n",
        "            self.data.append(series.loc[series.series_id == viz_id].copy().reset_index())\n",
        "\n",
        "    def downsample_seq_generate_features(self, feat, downsample_factor):\n",
        "        if len(feat) % downsample_factor != 0:\n",
        "            feat = np.concatenate([feat, np.zeros(downsample_factor - ((len(feat)) % downsample_factor)) + feat[-1]])\n",
        "        feat = np.reshape(feat, (-1, downsample_factor))\n",
        "        feat_mean = np.mean(feat, 1)\n",
        "        feat_std = np.std(feat, 1)\n",
        "        feat_median = np.median(feat, 1)\n",
        "        feat_max = np.max(feat, 1)\n",
        "        feat_min = np.min(feat, 1)\n",
        "\n",
        "        return np.dstack([feat_mean, feat_std, feat_median, feat_max, feat_min])[0]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = self.data[index][['anglez', 'enmo']].values.astype(np.float32)\n",
        "        X = np.concatenate([self.downsample_seq_generate_features(X[:, i], 12) for i in range(X.shape[1])], -1)\n",
        "        X = torch.from_numpy(X)\n",
        "        return X\n",
        "\n",
        "test_ds = SleepDataset(test_series.series_id.unique(), test_series)\n",
        "del test_series\n",
        "gc.collect()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-18T23:14:08.835380Z",
          "iopub.status.busy": "2023-10-18T23:14:08.834833Z",
          "iopub.status.idle": "2023-10-18T23:14:09.014057Z",
          "shell.execute_reply": "2023-10-18T23:14:09.012769Z"
        },
        "papermill": {
          "duration": 0.185209,
          "end_time": "2023-10-18T23:14:09.016533",
          "exception": false,
          "start_time": "2023-10-18T23:14:08.831324",
          "status": "completed"
        },
        "tags": [],
        "id": "4AvJg7kiGTaN",
        "outputId": "7333b554-8af2-4670-92ab-5a3402685fe0",
        "colab": {
          "referenced_widgets": [
            "ad18c5106dd04c6c8774e0776e7c33d6"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad18c5106dd04c6c8774e0776e7c33d6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "execution_count": 5,
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "22"
            ]
          },
          "metadata": {}
        }
      ],
      "id": "4AvJg7kiGTaN"
    },
    {
      "cell_type": "code",
      "source": [
        "max_chunk_size = 24*60*100\n",
        "min_interval = 30"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-18T23:14:09.023356Z",
          "iopub.status.busy": "2023-10-18T23:14:09.022748Z",
          "iopub.status.idle": "2023-10-18T23:14:09.027526Z",
          "shell.execute_reply": "2023-10-18T23:14:09.026253Z"
        },
        "papermill": {
          "duration": 0.010196,
          "end_time": "2023-10-18T23:14:09.029435",
          "exception": false,
          "start_time": "2023-10-18T23:14:09.019239",
          "status": "completed"
        },
        "tags": [],
        "id": "j49G_69nGTaN"
      },
      "execution_count": null,
      "outputs": [],
      "id": "j49G_69nGTaN"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gc\n",
        "\n",
        "# Assume max_chunk_size and min_interval are defined earlier in your code\n",
        "\n",
        "model = MultiResidualBiGRU(input_size=10, hidden_size=64, out_size=2, n_layers=5).to(device).eval()\n",
        "model.load_state_dict(torch.load('/kaggle/input/sleep-critical-point-train/model_best.pth', map_location=device))\n",
        "\n",
        "submission = pd.DataFrame()\n",
        "\n",
        "for i in range(len(test_ds)):\n",
        "    X = test_ds[i].half()\n",
        "\n",
        "    seq_len = X.shape[0]\n",
        "    h = None\n",
        "    pred = torch.zeros((len(X), 2)).half()\n",
        "\n",
        "    for j in range(0, seq_len, max_chunk_size):\n",
        "        y_pred, h = model(X[j: j + max_chunk_size].float(), h)\n",
        "        h = [hi.detach() for hi in h]\n",
        "        pred[j: j + max_chunk_size] = y_pred.detach()\n",
        "        del y_pred\n",
        "        gc.collect()\n",
        "\n",
        "    del h, X\n",
        "    gc.collect()\n",
        "    pred = pred.numpy()\n",
        "\n",
        "    series_id = ids[i]\n",
        "\n",
        "    days = len(pred) / (17280 / 12)\n",
        "    scores0, scores1 = np.zeros(len(pred), dtype=np.float16), np.zeros(len(pred), dtype=np.float16)\n",
        "\n",
        "    for index in range(len(pred)):\n",
        "        if pred[index, 0] == max(pred[max(0, index - min_interval):index + min_interval, 0]):\n",
        "            scores0[index] = max(pred[max(0, index - min_interval):index + min_interval, 0])\n",
        "        if pred[index, 1] == max(pred[max(0, index - min_interval):index + min_interval, 1]):\n",
        "            scores1[index] = max(pred[max(0, index - min_interval):index + min_interval, 1])\n",
        "\n",
        "    candidates_onset = np.argsort(scores0)[-max(1, round(days)):]\n",
        "    candidates_wakeup = np.argsort(scores1)[-max(1, round(days)):]\n",
        "\n",
        "    onset = test_ds.data[i][['step']].iloc[np.clip(candidates_onset * 12, 0, len(test_ds.data[i]) - 1)].astype(np.int32)\n",
        "    onset['event'] = 'onset'\n",
        "    onset['series_id'] = series_id\n",
        "    onset['score'] = scores0[candidates_onset]\n",
        "\n",
        "    wakeup = test_ds.data[i][['step']].iloc[np.clip(candidates_wakeup * 12, 0, len(test_ds.data[i]) - 1)].astype(np.int32)\n",
        "    wakeup['event'] = 'wakeup'\n",
        "    wakeup['series_id'] = series_id\n",
        "    wakeup['score'] = scores1[candidates_wakeup]\n",
        "\n",
        "    submission = pd.concat([submission, onset, wakeup], axis=0)\n",
        "\n",
        "    del onset, wakeup, candidates_onset, candidates_wakeup, scores0, scores1, pred, series_id\n",
        "    gc.collect()\n",
        "\n",
        "submission = submission.sort_values(['series_id', 'step']).reset_index(drop=True)\n",
        "submission['row_id'] = submission.index.astype(int)\n",
        "submission['score'] = submission['score'].fillna(submission['score'].mean())\n",
        "submission = submission[['row_id', 'series_id', 'step', 'event', 'score']]\n",
        "submission.to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-18T23:14:09.035610Z",
          "iopub.status.busy": "2023-10-18T23:14:09.035306Z",
          "iopub.status.idle": "2023-10-18T23:14:10.656048Z",
          "shell.execute_reply": "2023-10-18T23:14:10.654511Z"
        },
        "papermill": {
          "duration": 1.62678,
          "end_time": "2023-10-18T23:14:10.658889",
          "exception": false,
          "start_time": "2023-10-18T23:14:09.032109",
          "status": "completed"
        },
        "tags": [],
        "id": "mVU_6_3yGTaN"
      },
      "execution_count": null,
      "outputs": [],
      "id": "mVU_6_3yGTaN"
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-18T23:14:10.666141Z",
          "iopub.status.busy": "2023-10-18T23:14:10.665790Z",
          "iopub.status.idle": "2023-10-18T23:14:10.678202Z",
          "shell.execute_reply": "2023-10-18T23:14:10.677328Z"
        },
        "papermill": {
          "duration": 0.017502,
          "end_time": "2023-10-18T23:14:10.679758",
          "exception": false,
          "start_time": "2023-10-18T23:14:10.662256",
          "status": "completed"
        },
        "tags": [],
        "id": "ggZERUrkGTaO",
        "outputId": "5958622e-5776-46c9-b53f-56babfe5299d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 8,
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>row_id</th>\n",
              "      <th>series_id</th>\n",
              "      <th>step</th>\n",
              "      <th>event</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>038441c925bb</td>\n",
              "      <td>0</td>\n",
              "      <td>onset</td>\n",
              "      <td>0.237427</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>038441c925bb</td>\n",
              "      <td>144</td>\n",
              "      <td>wakeup</td>\n",
              "      <td>0.049408</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>03d92c9f6f8a</td>\n",
              "      <td>36</td>\n",
              "      <td>onset</td>\n",
              "      <td>0.179810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>03d92c9f6f8a</td>\n",
              "      <td>144</td>\n",
              "      <td>wakeup</td>\n",
              "      <td>0.016251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0402a003dae9</td>\n",
              "      <td>60</td>\n",
              "      <td>wakeup</td>\n",
              "      <td>0.013649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0402a003dae9</td>\n",
              "      <td>144</td>\n",
              "      <td>onset</td>\n",
              "      <td>0.094360</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   row_id     series_id  step   event     score\n",
              "0       0  038441c925bb     0   onset  0.237427\n",
              "1       1  038441c925bb   144  wakeup  0.049408\n",
              "2       2  03d92c9f6f8a    36   onset  0.179810\n",
              "3       3  03d92c9f6f8a   144  wakeup  0.016251\n",
              "4       4  0402a003dae9    60  wakeup  0.013649\n",
              "5       5  0402a003dae9   144   onset  0.094360"
            ]
          },
          "metadata": {}
        }
      ],
      "id": "ggZERUrkGTaO"
    }
  ]
}